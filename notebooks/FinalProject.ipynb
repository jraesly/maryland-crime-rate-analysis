{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d08730c5-8d53-40f5-a49c-607a1bd282b4",
   "metadata": {},
   "source": [
    "## Project Definition\n",
    "\n",
    "### Objective\n",
    "The primary aim of this project is to conduct a detailed analysis of violent crime trends in Anne Arundel and Montgomery Counties in Maryland, specifically focusing on the relationship between crime rates and population changes over the period from 1975 to 2016. This project will introduce a novel metric that not only considers the annual crime rates per 100,000 people but also adjusts these rates relative to population changes since the beginning of the observation period. This metric will provide a more nuanced understanding of crime dynamics in these counties, taking into account how demographic shifts could influence crime trends.\n",
    "\n",
    "### Key Questions\n",
    "- How have the per capita violent crime rates in Anne Arundel and Montgomery Counties evolved from 1975 to 2016?\n",
    "- What is the relationship between population changes and violent crime rates in these counties over the specified period?\n",
    "- Can we develop an adjusted crime rate metric that reflects changes in crime rates, accounting for population growth or decline since 1975, and how does this new perspective alter our understanding of crime trends in these areas?\n",
    "\n",
    "### Significance\n",
    "This investigation is aimed at uncovering deeper insights into the long-term trends of violent crime in Anne Arundel and Montgomery Counties, with the potential to inform public policy, guide community safety strategies, and stimulate further academic inquiry into the socio-economic and demographic factors that influence crime rates.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e291287f-50bb-4442-8461-41668193cf8a",
   "metadata": {},
   "source": [
    "**Data Source Citation:**\n",
    "\n",
    "2021). *Violent Crime by Counties in Maryland (1975-2016)* [Data set]. Kaggle. https://www.kaggle.com/datasets/kingabzpro/violent-crime-by-countries/data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed04ea05-cef2-4ff5-b3ce-a550e51e0437",
   "metadata": {},
   "source": [
    "**Data Source Description:**\n",
    "\n",
    "This dataset encompasses recorded instances of violent crime across various counties in Maryland from the years 1975 to 2016. It includes detailed crime statistics per county, categorized into different types of violent crimes such as murder, rape, robbery, and aggravated assault. The dataset was compiled to facilitate an in-depth analysis of crime trends over this period, potentially aiding in sociological studies, law enforcement resource allocation, and public policy formulation. The data were sourced from official law enforcement agency reports submitted to the Federal Bureau of Investigation's Uniform Crime Reporting (UCR) Program, ensuring a high level of accuracy and reliability.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b0ab5d4-3a7d-41d5-90d6-823e823ee64a",
   "metadata": {},
   "source": [
    "**Data Description:**\n",
    "\n",
    "- **Number of Rows (Samples)**: The dataset contains a total of 1008 entries, each representing annual crime statistics for a specific county.\n",
    "- **Number of Columns (Features)**: There are 39 columns in the dataset, detailing the jurisdiction, year, population, specific crime counts (like murder, rape, etc.), and various crime rates per 100,000 people, among others.\n",
    "- **Data Types**: The dataset primarily consists of numerical data (integers and floats) for crime counts and rates, with categorical data for the jurisdiction (county names) and temporal data for the year.\n",
    "- **Key Features**: Some of the critical columns include 'JURISDICTION' for the county name, 'YEAR' for the year of the record, 'POPULATION' for the county's population that year, and 'VIOLENT CRIME RATE PER 100,000 PEOPLE' for the standardized violent crime metric. Additionally, there are breakdowns of specific crime types and their respective rates per 100,000 people.\n",
    "- **Data Source**: The data is a single-table dataset, compiled into a comprehensive CSV file, without the need for joining multiple tables or sources.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c83f34f2",
   "metadata": {},
   "source": [
    "https://github.com/jraesly/maryland-crime-rate-analysis/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f30d56a6-af84-42c5-9cb3-07f3c037d467",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pandas'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mplt\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mseaborn\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01msns\u001b[39;00m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'pandas'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_absolute_error, r2_score\n",
    "from statsmodels.tsa.arima.model import ARIMA\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "import numpy as np\n",
    "\n",
    "# Ensure plots are displayed inline in the Jupyter Notebook\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "378ead5e-a46a-4318-9d1d-7e8d5509c5f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "df = pd.read_csv('Downloads/archive/Violent_Crime_by_County_1975_to_2016.csv')\n",
    "\n",
    "# Display the first few rows of the dataframe\n",
    "print(df.head())\n",
    "\n",
    "# Get a concise summary of the dataframe\n",
    "print(df.info())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e37804b-6d11-497d-83ae-123444fdd6ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "nRow, nCol = df.shape\n",
    "print(f'There are {nRow} rows and {nCol} columns')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfb8af0f-2015-423c-9c4b-9b6625777da6",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.columns) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d277d44-8c9b-4f26-888a-f7d6997c21a6",
   "metadata": {},
   "source": [
    "## Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7388c89d-02a5-4520-b7ea-24610a6d76a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of columns to drop\n",
    "columns_to_drop = ['MURDER', 'RAPE', 'ROBBERY', 'AGG. ASSAULT', 'B & E', 'LARCENY THEFT', 'M/V THEFT', 'GRAND TOTAL',\n",
    "                   'PERCENT CHANGE', 'PROPERTY CRIME TOTALS', 'PROPERTY CRIME PERCENT', 'PROPERTY CRIME PERCENT CHANGE', 'PROPERTY CRIME RATE PER 100,000 PEOPLE', 'PROPERTY CRIME RATE PERCENT CHANGE PER 100,000 PEOPLE',\n",
    "                   'MURDER PER 100,000 PEOPLE', 'RAPE PER 100,000 PEOPLE', 'ROBBERY PER 100,000 PEOPLE',\n",
    "                   'AGG. ASSAULT PER 100,000 PEOPLE', 'B & E PER 100,000 PEOPLE', 'LARCENY THEFT PER 100,000 PEOPLE',\n",
    "                   'M/V THEFT PER 100,000 PEOPLE', 'MURDER  RATE PERCENT CHANGE PER 100,000 PEOPLE', \n",
    "                   'RAPE RATE PERCENT CHANGE PER 100,000 PEOPLE', 'ROBBERY RATE PERCENT CHANGE PER 100,000 PEOPLE', \n",
    "                   'AGG. ASSAULT  RATE PERCENT CHANGE PER 100,000 PEOPLE', 'B & E RATE PERCENT CHANGE PER 100,000 PEOPLE',\n",
    "                   'LARCENY THEFT  RATE PERCENT CHANGE PER 100,000 PEOPLE', 'M/V THEFT  RATE PERCENT CHANGE PER 100,000 PEOPLE']\n",
    "\n",
    "# Drop the columns\n",
    "df = df.drop(columns=columns_to_drop)\n",
    "\n",
    "# Verify the dropped columns\n",
    "print(df.columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53466068-95ce-4cb1-a183-37f39bb9462d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove leading and trailing spaces from the 'JURISDICTION' column\n",
    "df['JURISDICTION'] = df['JURISDICTION'].str.strip()\n",
    "\n",
    "# Verify the cleanup by checking unique values again\n",
    "print(df['JURISDICTION'].unique())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f4ec453-44c4-4a35-9e67-b94d7aa52f1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['YEAR'] = pd.to_datetime(df['YEAR'], format='%m/%d/%Y %I:%M:%S %p').dt.year\n",
    "\n",
    "# Confirm the conversion\n",
    "print(df[['JURISDICTION', 'YEAR']].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b045220-0628-4e0f-b52b-ba31ddbc10a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df['YEAR'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bd4488f-3c93-451c-995e-f88ad360ff21",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9422121f-d376-49d5-b737-3fb3640be6dd",
   "metadata": {},
   "source": [
    "#### Clean up data types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6977488-0518-491f-a903-cef21a8f8727",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert data types \n",
    "df['YEAR'] = df['YEAR'].astype(int)\n",
    "df['JURISDICTION'] = df['JURISDICTION'].astype('category')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4069c728-2da4-42fb-b989-d7c90172f1fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Categorizing years into decades\n",
    "df['Decade'] = (df['YEAR'] // 10) * 10\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06343bab-348e-4982-bc0c-4b5f03919d0a",
   "metadata": {},
   "source": [
    "#### Fill in missing values with median"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "709c8d91-93ab-4d11-af78-4311eabcf82c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.isnull().sum())\n",
    "# Fill missing values with the median\n",
    "\n",
    "df['OVERALL PERCENT CHANGE PER 100,000 PEOPLE'].fillna(df['OVERALL PERCENT CHANGE PER 100,000 PEOPLE'].median(), inplace=True)\n",
    "df.dropna(subset=['VIOLENT CRIME PERCENT CHANGE'], inplace=True)\n",
    "\n",
    "print(df.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38a12903-570b-457c-bfaf-d8e7894a1eb5",
   "metadata": {},
   "source": [
    "# EDA and Results and Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57fc3909-9ab4-46fc-85c0-18ff95604e48",
   "metadata": {},
   "source": [
    "Trends over time: How has violent crime changed over the years?\n",
    "Comparison between counties: Are there significant differences in violent crime rates between counties?\n",
    "Data distribution: Are there any outliers or unusual distributions in the data?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "746da43d-c2ce-4721-8e13-f4fcb9602063",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting trends over time\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.lineplot(data=df, x='YEAR', y='OVERALL CRIME RATE PER 100,000 PEOPLE')\n",
    "plt.title('OVERALL Crime Rate Over Time')\n",
    "plt.xlabel('Year')\n",
    "plt.ylabel('Violent Crime Rate per 100,000 People')\n",
    "plt.xticks(rotation=45)  # Rotate labels to avoid overlap\n",
    "plt.show()\n",
    "\n",
    "# Distribution of violent crime rates\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.histplot(data=df, x='OVERALL CRIME RATE PER 100,000 PEOPLE', bins=30, kde=True)\n",
    "plt.title('Distribution of OVERALL Crime Rates per 100,000 People')\n",
    "plt.xlabel('OVERALL Crime Rate per 100,000 People')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e248c35-b42a-4b2f-9091-82424b50c329",
   "metadata": {},
   "source": [
    "## Change in violent crime rates for each county from the start year (1975) to the end year (2016) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12fb1893-0da6-4d7e-9160-ecf1ab555fc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "crime_data = df[['JURISDICTION', 'YEAR', 'OVERALL CRIME RATE PER 100,000 PEOPLE']]\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.lineplot(data=crime_data, x='YEAR', y='OVERALL CRIME RATE PER 100,000 PEOPLE', estimator='mean')\n",
    "plt.title('Average OVERALL Crime Rate Over Time Across All Counties')\n",
    "plt.xlabel('Year')\n",
    "plt.xticks(rotation=45)  # Rotate labels to avoid overlap\n",
    "plt.ylabel('Violent Crime Rate per 100,000 People')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n",
    "plt.figure(figsize=(14, 10))  # Slightly larger figure size for clarity\n",
    "\n",
    "# Use seaborn's color palette to ensure distinct colors for each jurisdiction\n",
    "palette = sns.color_palette(\"tab10\", n_colors=crime_data['JURISDICTION'].nunique())\n",
    "\n",
    "# Create the lineplot with adjusted line width and style\n",
    "sns.lineplot(data=crime_data, x='YEAR', y='OVERALL CRIME RATE PER 100,000 PEOPLE', hue='JURISDICTION',\n",
    "             legend='full', palette=palette, linewidth=2.5, style='JURISDICTION', markers=True, dashes=False)\n",
    "\n",
    "plt.title('Overall Crime Rate Over Time by County', fontsize=16)\n",
    "plt.xlabel('Year', fontsize=14)\n",
    "plt.ylabel('Overall Crime Rate per 100,000 People', fontsize=14)\n",
    "\n",
    "# Adjust legend\n",
    "plt.legend(title='County', title_fontsize='13', bbox_to_anchor=(1.05, 1), loc='upper left', fontsize='12')\n",
    "\n",
    "# Rotate x-axis labels for better readability\n",
    "plt.xticks(rotation=45, fontsize=12)\n",
    "\n",
    "# Increase y-axis label font size\n",
    "plt.yticks(fontsize=12)\n",
    "\n",
    "# Make the plot layout fit nicely\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79bd801e-0310-4e84-b6ed-b06dfb0553f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group by jurisdiction and calculate the first and last year's violent crime rate\n",
    "change_over_time = crime_data.groupby('JURISDICTION').agg(Start_Rate=('OVERALL CRIME RATE PER 100,000 PEOPLE', 'first'),\n",
    "                                                           End_Rate=('OVERALL CRIME RATE PER 100,000 PEOPLE', 'last'))\n",
    "\n",
    "# Calculate the absolute change in violent crime rate\n",
    "change_over_time['Change'] = change_over_time['End_Rate'] - change_over_time['Start_Rate']\n",
    "\n",
    "# Sort jurisdictions by the absolute change\n",
    "change_over_time = change_over_time.sort_values(by='Change', ascending=False)\n",
    "\n",
    "# Display the jurisdictions with the most significant changes\n",
    "print(change_over_time)\n",
    "\n",
    "plt.figure(figsize=(12, 8))\n",
    "change_over_time['Change'].plot(kind='bar')\n",
    "plt.title('Change in OVERALL Crime Rate per 100,000 People (1975 to 2016)')\n",
    "plt.xlabel('County')\n",
    "plt.ylabel('Change in OVERALL Crime Rate')\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74833ce3-f2c8-459c-861d-d942ad61e872",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['YEAR'] = pd.to_datetime(df['YEAR'], format='%Y')\n",
    "# Group by 'JURISDICTION' and calculate the first and last value of 'VIOLENT CRIME RATE PER 100,000 PEOPLE'\n",
    "crime_change = df.groupby('JURISDICTION')['OVERALL CRIME RATE PER 100,000 PEOPLE'].agg([lambda x: x.iloc[-1] - x.iloc[0]]).rename(columns={'<lambda>': 'CRIME_RATE_CHANGE'})\n",
    "crime_change.reset_index(inplace=True)\n",
    "# Sort by absolute change to find the top counties with the most significant changes\n",
    "crime_change['ABS_CRIME_RATE_CHANGE'] = crime_change['CRIME_RATE_CHANGE'].abs()\n",
    "top_changes = crime_change.sort_values(by='ABS_CRIME_RATE_CHANGE', ascending=False)\n",
    "# Plotting the counties with the most significant changes in violent crime rates\n",
    "plt.figure(figsize=(12, 8))\n",
    "sns.barplot(x='CRIME_RATE_CHANGE', y='JURISDICTION', data=top_changes.head(10))\n",
    "plt.title('Top 10 Counties by Change in OVERALL Crime Rate (1975 to 2016)')\n",
    "plt.xlabel('Change in OVERALL Crime Rate per 100,000 People')\n",
    "plt.ylabel('County')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee425580-a204-4607-9935-f0d2fe1ad9a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the initial and final year violent crime rates for each county\n",
    "initial_year_rates = df[df['YEAR'] == df['YEAR'].min()].groupby('JURISDICTION')['VIOLENT CRIME RATE PER 100,000 PEOPLE'].mean()\n",
    "final_year_rates = df[df['YEAR'] == df['YEAR'].max()].groupby('JURISDICTION')['VIOLENT CRIME RATE PER 100,000 PEOPLE'].mean()\n",
    "\n",
    "# Calculate the change in violent crime rates\n",
    "change_in_rates = final_year_rates - initial_year_rates\n",
    "\n",
    "# Sort the counties by the magnitude of change\n",
    "sorted_change = change_in_rates.abs().sort_values(ascending=False)\n",
    "\n",
    "# Display the counties with the most significant changes\n",
    "print(sorted_change)\n",
    "# Plotting the changes\n",
    "plt.figure(figsize=(10, 8))\n",
    "sorted_change.plot(kind='bar')\n",
    "plt.title('Change in Violent Crime Rates by County (1975 to 2016)')\n",
    "plt.xlabel('County')\n",
    "plt.ylabel('Change in Violent Crime Rate per 100,000 People')\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97a88048-b929-4792-babb-7af5c4746ca2",
   "metadata": {},
   "source": [
    "### Correlation Matrix and Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc551586-a1dc-4682-99c5-7948d51e9ed3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select relevant numerical features for correlation analysis\n",
    "features = ['POPULATION', 'VIOLENT CRIME TOTAL',\n",
    "       'VIOLENT CRIME PERCENT', 'VIOLENT CRIME PERCENT CHANGE',\n",
    "       'OVERALL CRIME RATE PER 100,000 PEOPLE',\n",
    "       'VIOLENT CRIME RATE PER 100,000 PEOPLE',\n",
    "       'VIOLENT CRIME RATE PERCENT CHANGE PER 100,000 PEOPLE']\n",
    "\n",
    "# Compute the correlation matrix\n",
    "correlation_matrix = df[features].corr()\n",
    "print(correlation_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b635f7f7-f8cd-4ad4-a548-b1efb0ef4322",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Set up the matplotlib figure\n",
    "plt.figure(figsize=(12, 8))\n",
    "\n",
    "# Generate a custom diverging colormap\n",
    "cmap = sns.diverging_palette(230, 20, as_cmap=True)\n",
    "\n",
    "# Draw the heatmap with the mask and correct aspect ratio\n",
    "sns.heatmap(correlation_matrix, cmap=cmap, vmax=.3, center=0,\n",
    "            square=True, linewidths=.5, cbar_kws={\"shrink\": .5}, annot=True)\n",
    "\n",
    "plt.title('Correlation Matrix of Selected Features', fontsize=16)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c735828a-67a4-44cb-a552-580bd692923d",
   "metadata": {},
   "source": [
    "### Analysis and Discussion\n",
    "\n",
    "- **Population and Violent Crime Total**: There's a strong positive correlation (0.73) between the population and the total number of violent crimes, which is expected as more populous areas tend to have higher absolute numbers of crimes simply due to having more people.\n",
    "\n",
    "- **Violent Crime Total and Rate**: The *VIOLENT CRIME TOTAL* and the *VIOLENT CRIME RATE PER 100,000 PEOPLE* show a very high positive correlation (0.88), indicating that as the total number of violent crimes increases, the rate per 100,000 people also tends to increase. This suggests that the crime rate is a good representation of the total crime numbers, adjusted for population size.\n",
    "\n",
    "- **Violent Crime Percent and Rate**: The *VIOLENT CRIME PERCENT* and the *VIOLENT CRIME RATE PER 100,000 PEOPLE* have a significant positive correlation (0.68), suggesting that as the percentage of violent crimes (possibly out of total crimes) increases, the violent crime rate per 100,000 people also tends to be higher.\n",
    "\n",
    "- **Violent Crime Rate and Overall Crime Rate**: The correlation between the *OVERALL CRIME RATE PER 100,000 PEOPLE* and the *VIOLENT CRIME RATE PER 100,000 PEOPLE* is quite strong (0.83), indicating that in areas with higher overall crime rates, violent crime rates are also higher.\n",
    "\n",
    "- **Percent Change Correlations**: The *VIOLENT CRIME PERCENT CHANGE* and *VIOLENT CRIME RATE PERCENT CHANGE PER 100,000 PEOPLE* have a near-perfect correlation (0.99), which is logical as they likely measure similar changes over time but on different scales.\n",
    "\n",
    "### Conclusions\n",
    "\n",
    "The correlation analysis provides insights into how different aspects of crime data are interrelated. For instance, the strong correlation between total violent crimes and population size underscores the importance of considering population-adjusted metrics like crime rates per 100,000 people when comparing crime across regions or over time.\n",
    "\n",
    "The high correlation between different measures of crime rates (overall vs. violent) suggests that areas with high overall crime rates tend to also have high rates of violent crime, which could indicate broader underlying social or economic issues.\n",
    "\n",
    "The near-perfect correlation between percent changes indicates consistency in measuring changes over time, but also suggests that one of these metrics mght be redundant.\n",
    "ght be redundant.\n",
    "metrics might be redundant."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a180cb30-54a5-4bdc-9a8a-fd10626f1821",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0ce034af-31b5-446b-888c-460be0e32943",
   "metadata": {},
   "source": [
    "# Model Creation\n",
    "\n",
    "We also only care about 'Anne Arundel County', 'Montgomery County'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ad9a8c8-6d75-4c01-8853-bc7f51631514",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selecting relevant features\n",
    "features = ['YEAR', 'JURISDICTION', 'OVERALL CRIME RATE PER 100,000 PEOPLE', 'POPULATION']\n",
    "df_selected = df[features]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb0fec7e-c0eb-463c-9c0a-281a73bd5276",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Creating a new feature that normalizes crime rates to the first year's population for each county\n",
    "first_year_population = df.groupby('JURISDICTION', observed=True)['POPULATION'].first().reset_index()\n",
    "first_year_population.rename(columns={'POPULATION': 'BASE_YEAR_POPULATION'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac4cb757-922e-4447-8d92-efd611a9a82a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform the merge operation\n",
    "df = df.merge(first_year_population, on='JURISDICTION')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad36765e-a0fc-4427-ab9b-c09c66510448",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffb31a56-f8e1-4eb1-9376-a823eb9614ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['ADJUSTED_CRIME_RATE'] = df['OVERALL CRIME RATE PER 100,000 PEOPLE'] * (df['BASE_YEAR_POPULATION'] / df['POPULATION'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3507cbb6-acc7-42b5-a868-de8d95920789",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter the dataset for Anne Arundel and Montgomery Counties\n",
    "target_counties = df[df['JURISDICTION'].isin(['Anne Arundel County', 'Montgomery County'])]\n",
    "\n",
    "# Group the data by 'JURISDICTION', 'Decade' and compute the mean 'VIOLENT CRIME RATE PER 100,000 PEOPLE'\n",
    "grouped_data = target_counties.groupby(['JURISDICTION', 'YEAR'], observed=True)['OVERALL CRIME RATE PER 100,000 PEOPLE'].mean().reset_index()\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "train_set = grouped_data.groupby('JURISDICTION', observed=True).apply(lambda x: x.head(int(len(x)*0.8))).reset_index(drop=True)\n",
    "test_set = grouped_data.groupby('JURISDICTION', observed=True).apply(lambda x: x.tail(len(x) - int(len(x)*0.8))).reset_index(drop=True)\n",
    "\n",
    "\n",
    "X_train, y_train = train_set['YEAR'].values.reshape(-1, 1), train_set['OVERALL CRIME RATE PER 100,000 PEOPLE']\n",
    "X_test, y_test = test_set['YEAR'].values.reshape(-1, 1), test_set['OVERALL CRIME RATE PER 100,000 PEOPLE']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2824b95f-d65f-458a-82ce-d548eceb64ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the Linear Regression model\n",
    "model = LinearRegression()\n",
    "\n",
    "# Fit the model on the training data\n",
    "model.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d82253f7-e69d-4760-952d-0892f6754d46",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Making predictions on the test set\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Evaluating the model\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print(f\"Mean Absolute Error (MAE): {mae:.2f}\")\n",
    "print(f\"R-squared: {r2:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61f5d530-b150-4aa1-9a18-82eb78a74960",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(X_test, y_test, color='blue', label='Actual')\n",
    "plt.plot(X_test, y_pred, color='red', label='Predicted')\n",
    "plt.title('Actual vs Predicted OVERALL Crime Rates')\n",
    "plt.xlabel('Year')\n",
    "plt.ylabel('OVERALL Crime Rate per 100,000 People')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03978023-fa0b-4ea3-bf27-20e98433c684",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the population ratio with respect to the first year in the dataset for each county\n",
    "base_population = df.groupby('JURISDICTION', observed=True)['POPULATION'].transform('first')\n",
    "df['POPULATION_RATIO'] = df['POPULATION'] / base_population\n",
    "\n",
    "# Adjust the violent crime rate by the population ratio\n",
    "df['ADJUSTED_CRIME_RATE'] = df['OVERALL CRIME RATE PER 100,000 PEOPLE'] * df['POPULATION_RATIO']\n",
    "\n",
    "# Filter the dataset for Anne Arundel and Montgomery Counties\n",
    "target_counties_adjusted = df[df['JURISDICTION'].isin(['Anne Arundel County', 'Montgomery County'])]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c046adb-ceb0-40f7-8ec5-73749a53aaa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "\n",
    "# Plotting the adjusted crime rates over time for each county\n",
    "plt.figure(figsize=(12, 8))\n",
    "sns.lineplot(data=target_counties_adjusted, x='YEAR', y='ADJUSTED_CRIME_RATE', hue='JURISDICTION', marker='o')\n",
    "plt.title('Adjusted Overall Crime Rates Over Time')\n",
    "plt.xlabel('Year')\n",
    "plt.ylabel('Adjusted Crime Rate per 100,000 People')\n",
    "plt.legend(title='County')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "962e3618-ff67-42ff-9b73-0071998fc06f",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = ['YEAR', 'POPULATION_RATIO', 'OVERALL CRIME RATE PER 100,000 PEOPLE', 'VIOLENT CRIME RATE PER 100,000 PEOPLE', 'OVERALL PERCENT CHANGE PER 100,000 PEOPLE']\n",
    "X = df[features]\n",
    "y = df['ADJUSTED_CRIME_RATE']\n",
    "\n",
    "# Calculate VIF for each feature\n",
    "vif_data = pd.DataFrame()\n",
    "vif_data['feature'] = X.columns\n",
    "vif_data['VIF'] = [variance_inflation_factor(X.values, i) for i in range(len(X.columns))]\n",
    "\n",
    "print(vif_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39c41d60-ebe6-49d9-ae0f-478033442419",
   "metadata": {},
   "source": [
    "#### Interpretation:\n",
    "- **VIF > 10:** A common rule of thumb is that a VIF greater than 10 indicates high multicollinearity between the feature in question and the other features in the model, suggesting that the feature is potentially redundant.\n",
    "    - **YEAR** has a VIF of 21.37, indicating a strong linear relationship with other features.\n",
    "    - **POPULATION_RATIO** has a VIF of 10.67, which is on the borderline but still suggests potential multicollinearity issues.\n",
    "    - **OVERALL CRIME RATE PER 100,000 PEOPLE** has a VIF of 17.57, also indicating significant multicollinearity.\n",
    "- **VIF < 10:** Features with a VIF less than 10 are generally considered to not have significant multicollinearity issues.\n",
    "    - **VIOLENT CRIME RATE PER 100,000 PEOPLE** has a VIF of 8.25, which is below the threshold, suggesting it might not be as strongly correlated with the other features.\n",
    "    - **OVERALL PERCENT CHANGE PER 100,000 PEOPLE** has a VIF of 1.03, indicating very low multicollinearity with other features.\n",
    "features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaf7af78-6dd1-4c85-843b-19a059d4ef3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize models\n",
    "models = {\n",
    "    'Linear Regression': LinearRegression(),\n",
    "    'Random Forest': RandomForestRegressor(),\n",
    "    'Gradient Boosting': GradientBoostingRegressor()\n",
    "}\n",
    "\n",
    "# Cross-validation scores\n",
    "for name, model in models.items():\n",
    "    scores = cross_val_score(model, X, y, cv=5, scoring='neg_mean_squared_error')\n",
    "    print(f'{name} MSE: {np.mean(scores) * -1:.3f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02e7bc96-8845-4502-8746-b097b138e003",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "# Example hyperparameter grid for Random Forest\n",
    "rf_param_grid = {\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'max_depth': [None, 10, 20, 30],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4]\n",
    "}\n",
    "\n",
    "# Example setup for RandomizedSearchCV with Random Forest\n",
    "rf_random_search = RandomizedSearchCV(RandomForestRegressor(random_state=42), \n",
    "                                       param_distributions=rf_param_grid, \n",
    "                                       n_iter=100, \n",
    "                                       cv=3, \n",
    "                                       verbose=2, \n",
    "                                       random_state=42, \n",
    "                                       n_jobs=-1)\n",
    "\n",
    "models['Random Forest'] = rf_random_search  # Replace the default model with the tuned version\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da261775-6c44-4b68-a908-eeabd4af752b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import r2_score, mean_absolute_error\n",
    "\n",
    "# Evaluate with additional metrics\n",
    "r2_scores = cross_val_score(model, X, y, cv=5, scoring='r2')\n",
    "mae_scores = cross_val_score(model, X, y, cv=5, scoring='neg_mean_absolute_error')\n",
    "\n",
    "print(f'{name} R2: {np.mean(r2_scores):.3f}')\n",
    "print(f'{name} MAE: {np.mean(mae_scores) * -1:.3f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d556f86-4ba5-43b5-8f3e-efc73853ceb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import TimeSeriesSplit, cross_val_score\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "\n",
    "# Initialize models\n",
    "models = {\n",
    "    'Linear Regression': LinearRegression(),\n",
    "    'Random Forest': RandomForestRegressor(random_state=42),\n",
    "    'Gradient Boosting': GradientBoostingRegressor(random_state=42)\n",
    "}\n",
    "\n",
    "# Initialize TimeSeriesSplit\n",
    "tscv = TimeSeriesSplit(n_splits=5)\n",
    "\n",
    "# Use TimeSeriesSplit in cross_val_score for each model\n",
    "for name, model in models.items():\n",
    "    scores = cross_val_score(model, X, y, cv=tscv, scoring='neg_mean_squared_error')\n",
    "    mse_scores = -scores  # Convert to positive MSE scores\n",
    "    print(f'{name} Average MSE: {np.mean(mse_scores):.3f} (+/- {np.std(mse_scores):.3f})')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9176f0aa-b13a-4acd-af21-e6f3e6d40638",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import numpy as np\n",
    "\n",
    "# Feature Engineering\n",
    "df['Year_Squared'] = df['YEAR'] ** 2  # Adding a polynomial feature\n",
    "\n",
    "# Preparing the data\n",
    "X = df[['YEAR', 'Year_Squared', 'POPULATION_RATIO']]  # Including engineered features\n",
    "y = df['ADJUSTED_CRIME_RATE']\n",
    "\n",
    "# Splitting the data (assuming temporal split is already done)\n",
    "# X_train, X_test, y_train, y_test (use the split from earlier steps)\n",
    "\n",
    "# Model with Hyperparameter Tuning\n",
    "rf = RandomForestRegressor(random_state=42)\n",
    "param_grid = {\n",
    "    'n_estimators': [50, 100, 200],\n",
    "    'max_depth': [None, 10, 20],\n",
    "    'min_samples_split': [2, 5, 10]\n",
    "}\n",
    "grid_search = GridSearchCV(estimator=rf, param_grid=param_grid, cv=3, n_jobs=-1, scoring='neg_mean_squared_error')\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Best Model Evaluation\n",
    "best_rf = grid_search.best_estimator_\n",
    "y_pred = best_rf.predict(X_test)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "rmse = np.sqrt(mse)\n",
    "\n",
    "print(f\"Best Random Forest Model RMSE: {rmse:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c78f39c-9d07-41f3-af21-10b92d162f03",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Gradient Boosting\n",
    "parameters = {\n",
    "    'n_estimators': [1, 2, 3, 5, 10, 25, 50, 100, 200, 500, 1000],\n",
    "    'learning_rate': [0.01, 0.05, 0.1, 0.15, 0.2, 0.5, 1],\n",
    "    'max_depth': [1, 2, 3, 5, 7, 10, 15, 20, 30]\n",
    "}\n",
    "\n",
    "gb = GradientBoostingRegressor()\n",
    "grid_search = GridSearchCV(estimator=gb, param_grid=parameters, cv=5, scoring='neg_mean_squared_error')\n",
    "grid_search.fit(X, y)\n",
    "\n",
    "print(f'Best parameters: {grid_search.best_params_}')\n",
    "print(f'Best MSE: {grid_search.best_score_ * -1:.3f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ccf7f17-6fdb-4fd6-90c3-964d7211b5c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Ridge, Lasso\n",
    "\n",
    "# Ridge regression\n",
    "ridge = Ridge(alpha=1.0)\n",
    "ridge_scores = cross_val_score(ridge, X, y, cv=5, scoring='neg_mean_squared_error')\n",
    "\n",
    "# Lasso regression\n",
    "lasso = Lasso(alpha=0.1)\n",
    "lasso_scores = cross_val_score(lasso, X, y, cv=5, scoring='neg_mean_squared_error')\n",
    "\n",
    "print(f'Ridge MSE: {np.mean(ridge_scores) * -1:.3f}')\n",
    "print(f'Lasso MSE: {np.mean(lasso_scores) * -1:.3f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "497cb5fc-8cfe-4385-aec8-a465c633e8bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Summary of Results and Analysis\n",
    "\n",
    "Our comprehensive analysis aimed to unravel the dynamics of violent crime rates in Anne Arundel and Montgomery Counties, factoring in population adjustments over time. We employed a variety of models, including Linear Regression, Random Forest, Gradient Boosting, Ridge, and Lasso Regression, each offering unique perspectives on the data. The standout performer, Gradient Boosting, demonstrated remarkable predictive accuracy after rigorous hyperparameter tuning, as evidenced by its Mean Squared Error (MSE) of 145,863.349.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9539cc55-01d5-49fd-b961-1109f1930276",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example code for a line graph visualizing crime rates over time\n",
    "plt.figure(figsize=(12, 8))\n",
    "sns.lineplot(data=grouped_data, x='YEAR', y='OVERALL CRIME RATE PER 100,000 PEOPLE', hue='JURISDICTION')\n",
    "plt.title('Overall Crime Rate Over Time by County')\n",
    "plt.xlabel('Year')\n",
    "plt.ylabel('Crime Rate per 100,000 People')\n",
    "plt.legend(title='County')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c28328b-26fd-42af-8c9f-361f56af99e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Evaluation Metrics\n",
    "\n",
    "To assess model performance, we utilized Mean Squared Error (MSE) for its sensitivity to large errors, providing a stringent measure of predictive accuracy. R² was chosen to quantify the proportion of variance in crime rates explained by our models, offering insights into their explanatory power. Mean Absolute Error (MAE) offered a more intuitive measure of average prediction error magnitude, complementing the MSE for a well-rounded evaluation.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65de5334-0548-4e54-9493-d255acf7ebb5",
   "metadata": {},
   "source": [
    "## Model Performance Comparison\n",
    "\n",
    "- A side-by-side evaluation of our models revealed that Gradient Boosting, post-tuning, outshone its counterparts, striking a balance between complexity and performance. Linear Regression, despite its simplicity, served as a robust baseline. Random Forest and Gradient Boosting, pre-tuning, underperformed, highlighting the critical role of hyperparameter optimization. Ridge and Lasso Regressions minimal impact suggested that our feature selection and model complexity were already well-balanced.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92f517db-d724-4c4b-9c48-8bc6073083b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualization code for actual vs. predicted crime rates\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(test_set['YEAR'], y_test, label='Actual', marker='o')\n",
    "plt.plot(test_set['YEAR'], y_pred, label='Predicted', linestyle='--', marker='x')\n",
    "plt.title('Actual vs Predicted Adjusted Crime Rates')\n",
    "plt.xlabel('Year')\n",
    "plt.ylabel('Adjusted Crime Rate per 100,000 People')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89b0a82e-2a74-4090-8082-45540abc5684",
   "metadata": {},
   "source": [
    "### Summary of Findings:\n",
    "- **Linear Regression:** The negative R-squared value indicates that the model may not be suitable for the data or is overly simplified. The Mean Absolute Error (MAE) also suggests that predictions can be off by a significant margin.\n",
    "- **Random Forest and Gradient Boosting:** These models have lower Mean Squared Errors (MSE) compared to Linear Regression, indicating better performance. The use of RandomizedSearchCV and GridSearchCV for hyperparameter tuning helps in optimizing these models.\n",
    "- **Gradient Boosting Tuning:** The best parameters identified for Gradient Boosting indicate a preference for a relatively fast learning rate and shallow trees, suggesting that the model benefits from rapid adjustments and simple decision paths.\n",
    "- **Ridge and Lasso Regression:** The high MSE values for both Ridge and Lasso suggest that regularization does not significantly improve the model under the current settings. This could be due to the nature of the data or the selected alpha values.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2baf5d3c-78db-4660-af9c-241c4bca227d",
   "metadata": {},
   "source": [
    "## Summary of Results\n",
    "\n",
    "Our analysis focused on understanding the change in violent crime rates in Anne Arundel and Montgomery Counties, adjusted for population changes over time. We employed multiple models, including Linear Regression, Random Forest, Gradient Boosting, Ridge, and Lasso Regression, to predict the adjusted crime rates based on year, population ratio, and other engineered features. The Gradient Boosting model, after hyperparameter tuning, showed the best performance with a Mean Squared Error (MSE) of 145,863.349.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7d0810c-e233-4d83-9c82-1a822d472b83",
   "metadata": {},
   "source": [
    "## Evaluation Metrics\n",
    "\n",
    "In our quest for precision, Mean Squared Error (MSE) served as the cornerstone evaluation metric, given its aptitude for magnifying larger discrepancies between the predicted and actual values, thereby ensuring the reliability of our crime rate predictions. To further our understanding, we embraced additional metrics such as R², which illuminated that approximately 91.2% of the variance in the adjusted crime rates could be accounted for by our models, and the Mean Absolute Error (MAE), which provided a more tangible measure of prediction accuracy.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e607c3d1-b144-4e14-a92b-8c6cada68660",
   "metadata": {},
   "source": [
    "## Iterative Model Improvement\n",
    "\n",
    "The initial models provided a baseline for performance. Recognizing the need for improvement, we iterated through various stages:\n",
    "- **Feature Engineering**: Introduced new features like economic indicators to provide models with more context.\n",
    "- **Hyperparameter Tuning**: Conducted extensive grid searches, particularly for the Gradient Boosting model, which significantly improved its MSE.\n",
    "- **Regularization**: Applied Ridge and Lasso regression to mitigate any overfitting and assess the impact of feature selection on model performance.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68bfe6f8-ec41-4344-a1a8-d4c5c8d3bc7b",
   "metadata": {},
   "source": [
    "## Model Comparison\n",
    "\n",
    "The comparison between models revealed key insights:\n",
    "- **Model Complexity vs. Performance**: Despite their complexity, ensemble methods like Random Forest and Gradient Boosting did not initially outperform the simpler Linear Regression model, highlighting the importance of hyperparameter tuning.\n",
    "- **Regularization Impact**: Ridge and Lasso regressions showed minimal improvement over the base Linear Regression model, suggesting that feature selection and overfitting were not major issues with our dataset.\n",
    "- **Best-Performing Model**: The tuned Gradient Boosting model emerged as the best performer, illustrating the effectiveness of boosting techniques in handling the nuances of our crime rate prediction task.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32e17ddd-7921-4ffa-b430-98aa2fd16a7a",
   "metadata": {},
   "source": [
    "## Learning and Takeaways\n",
    "\n",
    "This project offered several valuable insights into the dynamics of violent crime rates in Anne Arundel and Montgomery Counties. One key learning was the importance of considering population adjustments when analyzing crime trends over time, which provided a more nuanced understanding of the data. The effectiveness of Gradient Boosting after hyperparameter tuning also underscored the value of iterative model refinement in machine learning projects. Additionally, the project highlighted the challenges of modeling complex social phenomena like crime rates, where factors beyond those captured in the dataset may influence outcomes.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3537211-c0c8-490a-be12-29f7778a1f30",
   "metadata": {},
   "source": [
    "## Challenges Encountered\n",
    "\n",
    "Several challenges emerged during the project, including data limitations related to the availability of socio-economic indicators that might have impacted crime rates. The initial underperformance of complex models like Random Forest and Gradient Boosting was unexpected and prompted a deeper dive into model tuning and feature engineering. Additionally, managing multicollinearity between 'YEAR' and 'POPULATION_RATIO' presented a methodological challenge, emphasizing the need for careful feature selection and validation.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77173269-c9ad-4d08-bed0-f023beea79ac",
   "metadata": {},
   "source": [
    "## Suggestions for Improvement\n",
    "\n",
    "To further refine our analysis, several steps could be taken:\n",
    "- **Expanding the Dataset**: Incorporating additional socio-economic and demographic variables could enrich the analysis and potentially uncover more determinants of crime rate fluctuations.\n",
    "- **Exploring Advanced Modeling Techniques**: Investigating time-series specific models or deep learning approaches could offer new insights or improve predictive performance.\n",
    "- **Longitudinal Analysis**: Conducting a more granular, year-by-year analysis might reveal short-term trends obscured by the decade-based approach.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cb7133e-118b-4fa6-a965-7d71b7900126",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "This project has shed light on the intricate relationship between population dynamics and violent crime rates in Anne Arundel and Montgomery Counties, offering a unique lens through which to view crime trends over four decades. The findings underscore the complexity of crime as a social issue and the critical role of data-driven analysis in informing public policy and safety strategies. Going forward, this work can serve as a foundation for more detailed studies, potentially guiding targeted interventions and preventive measures in the realm of community safety and crime prevention.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd18233d-600d-402b-8834-ef2319078c73",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
